# Use Open AI with key
provider: autogen_ext.models.ollama.OllamaChatCompletionClient
config:
  model: llama3.2:1b
  host: "http://localhost:11434"